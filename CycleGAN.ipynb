{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CycleGAN\n",
    "\n",
    "Based on:\n",
    " - https://github.com/AYLIEN/gan-intro/blob/master/gan.py\n",
    " - https://hardikbansal.github.io/CycleGANBlog/\n",
    "\n",
    "Dataset:\n",
    " - http://www.cs.toronto.edu/~rgrosse/courses/csc321_2018/assignments/a4-code.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "#tf.enable_eager_execution()\n",
    "#tf.executing_eagerly()\n",
    "\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "tf.set_random_seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import and preview the Apple and Windows emojis dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _parse_function(filename):\n",
    "    \"\"\" Get tensor from filename \"\"\"\n",
    "    image_string = tf.read_file(filename)\n",
    "    image_decoded = tf.image.decode_png(image_string, channels=4) # RGBA images\n",
    "    # They're probably already all 72x72, but just to make sure -- causes issues?\n",
    "    #image_resized = tf.image.resize_images(image_decoded, [72, 72])\n",
    "    # Normalize to be between -1 and 1\n",
    "    image_cast = tf.cast(image_decoded, tf.float32)\n",
    "    image_norm = tf.subtract(tf.divide(image_cast, [127.5]), 1)\n",
    "    return image_norm\n",
    "\n",
    "def train_input_fn(num_epochs=1, batch_size=1):\n",
    "    \"\"\" Get tensors of training data for image sets A and B \"\"\"\n",
    "    apple = tf.data.Dataset.list_files(\"emojis/Apple/*.png\").map(_parse_function)\n",
    "    windows = tf.data.Dataset.list_files(\"emojis/Windows/*.png\").map(_parse_function)\n",
    "    \n",
    "    apple_iter = apple.shuffle(10000).batch(batch_size).make_initializable_iterator()\n",
    "    windows_iter = windows.shuffle(10000).batch(batch_size).make_initializable_iterator()\n",
    "    return {\n",
    "        'A': apple_iter,\n",
    "        'B': windows_iter\n",
    "    }\n",
    "\n",
    "def test_input_fn(num_epochs=1, batch_size=1):\n",
    "    \"\"\" Get tensors of testing data for image sets A and B \"\"\"\n",
    "    apple = tf.data.Dataset.list_files(\"emojis/Test_Apple/*.png\").map(_parse_function)\n",
    "    windows = tf.data.Dataset.list_files(\"emojis/Test_Windows/*.png\").map(_parse_function)\n",
    "    \n",
    "    apple_iter = apple.shuffle(10000).batch(batch_size).make_initializable_iterator()\n",
    "    windows_iter = windows.shuffle(10000).batch(batch_size).make_initializable_iterator()\n",
    "    return {\n",
    "        'A': apple_iter,\n",
    "        'B': windows_iter\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show(titles, input_data, num=20, cols=10):\n",
    "    with tf.Session() as sess:\n",
    "        \"\"\" Display the first images in a given dataset as a sanity check \"\"\"\n",
    "        assert len(titles) == len(input_data)\n",
    "        for i, (name,tensor) in enumerate(input_data.items()): # Plot each provided dataset (probably 2)\n",
    "            sess.run(tensor.initializer)\n",
    "            fig = plt.figure(figsize=(15, 3))\n",
    "            plt.axis('off')\n",
    "            plt.title(\"Dataset: \"+titles[i])\n",
    "            \n",
    "            # If we don't denormalize it, the coloring will be off\n",
    "            denormalized = tf.cast(tf.multiply(tf.add(tensor.get_next(),1),127.5), tf.uint8)\n",
    "\n",
    "            for j in range(num):\n",
    "                next_image = sess.run(denormalized)[0] # Only take first image in batch\n",
    "\n",
    "                ax = fig.add_subplot(np.ceil(num/cols), cols, j+1)\n",
    "                ax.grid(False)\n",
    "                ax.set_xticks([])\n",
    "                ax.set_yticks([])\n",
    "                plt.imshow(next_image)\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "#show([\"Train Apple\", \"Train Windows\"], train_input_fn())\n",
    "#show([\"Test Apple\", \"Test Windows\"], test_input_fn())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementing the GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2d(name, inputs, num_outputs, kernel_size, stride, padding, stddev=0.02, activation=tf.nn.relu):\n",
    "    with tf.variable_scope(name):\n",
    "        return tf.contrib.layers.conv2d(inputs, num_outputs, kernel_size, stride, padding,\n",
    "                                        activation_fn=activation,\n",
    "                                        weights_initializer=tf.truncated_normal_initializer(stddev=stddev),\n",
    "                                        biases_initializer=tf.constant_initializer(0.0))\n",
    "\n",
    "def deconv2d(name, inputs, num_outputs, kernel_size, stride, padding, stddev=0.02, activation=tf.nn.relu):\n",
    "    with tf.variable_scope(name):\n",
    "        return tf.contrib.layers.conv2d_transpose(inputs, num_outputs, kernel_size, stride, padding,\n",
    "                                                  activation_fn=activation,\n",
    "                                                  weights_initializer=tf.truncated_normal_initializer(stddev=stddev),\n",
    "                                                  biases_initializer=tf.constant_initializer(0.0))\n",
    "\n",
    "def resnet(name, inputs, num_outputs):\n",
    "    with tf.variable_scope(name):\n",
    "        r = tf.pad(inputs, [[0,0], [1,1], [1,1], [0,0]], \"REFLECT\")\n",
    "        r = conv2d(\"c1\", r, num_outputs, 3, 1, \"VALID\")\n",
    "        r = tf.pad(r, [[0,0], [1,1], [1,1], [0,0]], \"REFLECT\")\n",
    "        r = conv2d(\"c2\", r, num_outputs, 3, 1, \"VALID\", activation=None)\n",
    "        return tf.nn.relu(r + inputs)\n",
    "\n",
    "class CycleGAN:\n",
    "    def __init__(self,\n",
    "                 num_epochs=100,\n",
    "                 batch_size=16,\n",
    "                 img_width=72,\n",
    "                 img_height=72,\n",
    "                 img_layers=4,\n",
    "                 generator_residual_blocks=3,\n",
    "                 log_dir=\"logs\",\n",
    "                 check_dir=\"models\",\n",
    "                 restore=True):\n",
    "        self.num_epochs = num_epochs\n",
    "        self.batch_size = batch_size\n",
    "        self.img_width = img_width\n",
    "        self.img_height = img_height\n",
    "        self.img_layers = img_layers\n",
    "        self.log_dir = log_dir\n",
    "        self.check_dir = check_dir\n",
    "        self.restore = restore\n",
    "        self.data_format = 'channels_last'\n",
    "        self.generator_residual_blocks = generator_residual_blocks\n",
    "\n",
    "    def create_generator(self, name, input_layer):\n",
    "        l = tf.keras.layers\n",
    "        ngf = 8 # Filter depth for generator, what was used in tutorial\n",
    "\n",
    "        with tf.variable_scope(name):\n",
    "            # TODO\n",
    "            # - add instance norm, batch norm, group norm or something\n",
    "            # - add leaky ReLU\n",
    "            # - wrong sizes I think, so this probably won't work\n",
    "            g_c1 = conv2d(\"c1\", input_layer, ngf,   7, 1, \"VALID\")\n",
    "            g_c2 = conv2d(\"c2\", g_c1,        ngf*2, 3, 2, \"SAME\")\n",
    "            g_c3 = conv2d(\"c3\", g_c2,        ngf*4, 3, 1, \"SAME\")\n",
    "\n",
    "            assert self.generator_residual_blocks > 0\n",
    "            g_r = resnet(\"r1\", g_c3, ngf*4)\n",
    "            for i in range(self.generator_residual_blocks-1):\n",
    "                g_r = resnet(\"r\"+str(i+2), g_r, ngf*4)\n",
    "\n",
    "            g_c4 = deconv2d(\"c4\", g_r,  ngf*2,           3, 2, \"SAME\")\n",
    "            g_c5 = deconv2d(\"c5\", g_c4, ngf,             3, 2, \"SAME\")\n",
    "            g_c6 = conv2d(\"c6\",   g_c5, self.img_layers, 3, 2, \"SAME\", activation=None)\n",
    "\n",
    "            return tf.nn.tanh(g_c6, \"t1\") # Maybe not needed since I used ReLU for all of them?\n",
    "\n",
    "    def create_discriminator(self, name, input_layer):\n",
    "        l = tf.keras.layers\n",
    "        ndf = 16 # Filter depth for discriminator, what was used in tutorial\n",
    "\n",
    "        with tf.variable_scope(name):\n",
    "            d_c1 = conv2d(\"c1\", input_layer, ndf,   4, 2, \"SAME\")\n",
    "            d_c2 = conv2d(\"c2\", d_c1,        ndf*2, 4, 2, \"SAME\")\n",
    "            d_c3 = conv2d(\"c3\", d_c2,        ndf*4, 4, 2, \"SAME\")\n",
    "            d_c4 = conv2d(\"c4\", d_c3,        ndf*8, 4, 1, \"SAME\")\n",
    "            d_c5 = conv2d(\"c5\", d_c4,        1,     4, 1, \"SAME\", activation=None)\n",
    "            return d_c5\n",
    "\n",
    "    def cyclegan_model(self):\n",
    "        # Get image data directly from features or from \"image\" if it's a dictionary\n",
    "        #assert isinstance(input_data, dict) and len(input_data) == 2, \"input_data must include both images A and B\"\n",
    "        #image_A = input_data['A']\n",
    "        #image_B = input_data['B']\n",
    "        self.image_A = tf.placeholder(tf.float32,\n",
    "                                      [self.batch_size, self.img_width, self.img_height, self.img_layers],\n",
    "                                      name=\"input_A\")\n",
    "        self.image_B = tf.placeholder(tf.float32,\n",
    "                                      [self.batch_size, self.img_width, self.img_height, self.img_layers],\n",
    "                                      name=\"input_B\")\n",
    "        \n",
    "        # For keeping track of where we are in training, and restoring from checkpoints\n",
    "        self.global_step = tf.Variable(0, name=\"global_step\", trainable=False)\n",
    "        self.iteration = tf.Variable(0, name=\"iteration\", trainable=False)\n",
    "\n",
    "        # Create models\n",
    "        with tf.variable_scope(\"Model\") as scope:\n",
    "            # Generator on original images\n",
    "            self.gen_AtoB = self.create_generator(\"gen_AtoB\", self.image_A)\n",
    "            self.gen_BtoA = self.create_generator(\"gen_BtoA\", self.image_B)\n",
    "\n",
    "            # Discriminator on the original real images\n",
    "            self.disc_Areal = self.create_discriminator(\"discrim_A\", self.image_A)\n",
    "            self.disc_Breal = self.create_discriminator(\"discrim_B\", self.image_B)\n",
    "\n",
    "            scope.reuse_variables()\n",
    "\n",
    "            # Generate from fake back to original (for cycle consistency)\n",
    "            self.gen_AtoBtoA = self.create_generator(\"gen_BtoA\", self.gen_AtoB) # Reuse weights from BtoA\n",
    "            self.gen_BtoAtoB = self.create_generator(\"gen_AtoB\", self.gen_BtoA) # Reuse weights from AtoB\n",
    "\n",
    "            # Discriminators on the generated fake images\n",
    "            self.disc_Afake = self.create_discriminator(\"discrim_A\", self.gen_AtoB)\n",
    "            self.disc_Bfake = self.create_discriminator(\"discrim_B\", self.gen_BtoA)\n",
    "\n",
    "            # TODO\n",
    "            # - implement the image pool for performance and better convergence\n",
    "\n",
    "        #\n",
    "        # Loss functions\n",
    "        #\n",
    "        # Generator should by cycle consistent & we want the discriminator to output a 1, i.e. incorrect label\n",
    "        cyc_loss = tf.reduce_mean(tf.abs(self.image_A-self.gen_AtoBtoA)) + \\\n",
    "                   tf.reduce_mean(tf.abs(self.image_B-self.gen_BtoAtoB))\n",
    "        g_loss_A = self.cyc_loss*10 + tf.reduce_mean(tf.squared_difference(self.disc_Afake,1))\n",
    "        g_loss_B = self.cyc_loss*10 + tf.reduce_mean(tf.squared_difference(self.disc_Bfake,1))\n",
    "\n",
    "        # Discriminator should correctly classify the original real images and the generated fake images\n",
    "        d_loss_A = (tf.reduce_mean(tf.square(self.disc_Afake)) +\n",
    "                         tf.reduce_mean(tf.squared_difference(self.disc_Areal,1)))/2\n",
    "        d_loss_B = (tf.reduce_mean(tf.square(self.disc_Bfake)) +\n",
    "                         tf.reduce_mean(tf.squared_difference(self.disc_Breal,1)))/2\n",
    "\n",
    "        #\n",
    "        # Variables\n",
    "        #\n",
    "        variables = tf.trainable_variables()\n",
    "        d_A_vars = [v for v in variables if 'discrim_A' in v.name]\n",
    "        g_A_vars = [v for v in variables if 'gen_A' in v.name]\n",
    "        d_B_vars = [v for v in variables if 'discrim_B' in v.name]\n",
    "        g_B_vars = [v for v in variables if 'gen_B' in v.name]\n",
    "\n",
    "        #\n",
    "        # Optimization\n",
    "        #\n",
    "        self.learningRate = tf.placeholder(tf.float32, shape=[], name=\"learningRate\")\n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate=self.learningRate, beta1=0.5)\n",
    "        self.d_A_trainer = optimizer.minimize(d_loss_A, var_list=d_A_vars)\n",
    "        self.d_B_trainer = optimizer.minimize(d_loss_B, var_list=d_B_vars)\n",
    "        self.g_A_trainer = optimizer.minimize(g_loss_A, var_list=d_A_vars)\n",
    "        self.g_B_trainer = optimizer.minimize(g_loss_B, var_list=d_B_vars)\n",
    "        \n",
    "        #\n",
    "        # Summaries for TensorBoard\n",
    "        #\n",
    "        self.g_A_loss_summ = tf.summary.scalar(\"g_A_loss\", g_loss_A)\n",
    "        self.g_B_loss_summ = tf.summary.scalar(\"g_B_loss\", g_loss_B)\n",
    "        self.d_A_loss_summ = tf.summary.scalar(\"d_A_loss\", d_loss_A)\n",
    "        self.d_B_loss_summ = tf.summary.scalar(\"d_B_loss\", d_loss_B)\n",
    "    \n",
    "    def run(self):\n",
    "        # Define the networks\n",
    "        self.cyclegan_model()\n",
    "\n",
    "        # Saving content checkpoints and summaries to disk\n",
    "        saver = tf.train.Saver()\n",
    "        writer = tf.summary.FileWriter(self.log_dir)\n",
    "\n",
    "        if not os.path.exists(self.check_dir):\n",
    "            os.makedirs(self.check_dir)\n",
    "\n",
    "        with tf.Session() as sess:\n",
    "            tf.local_variables_initializer().run()\n",
    "            tf.global_variables_initializer().run()\n",
    "\n",
    "            # Get input images\n",
    "            input_data = train_input_fn(self.num_epochs, self.batch_size)\n",
    "            image_A_iter = input_data['A']\n",
    "            image_B_iter = input_data['B']\n",
    "            sess.run(image_A_iter, image_B_iter)\n",
    "\n",
    "            # Restore from last checkpoint\n",
    "            if restore:\n",
    "                chkpt_fname = tf.train.latest_checkpoint(self.check_dir)\n",
    "                saver.restore(sess, chkpt_fname)\n",
    "            \n",
    "            writer.add_graph(sess.graph)\n",
    "\n",
    "            # Run the training\n",
    "            for epoch in range(sess.run(self.global_step),self.num_epochs):\n",
    "                iteration = sess.run(self.iteration)\n",
    "                print(\"Epoch:\", epoch)\n",
    "                saver.save(sess, os.path.join(self.check_dir, \"cyclegan\"), global_step=epoch)\n",
    "                \n",
    "                # Decaying learning rate\n",
    "                if epoch < 100:\n",
    "                    currentLearningRate = 0.0002\n",
    "                else:\n",
    "                    currentLearningRate = 0.0002 - 0.0002*(epoch-100)/100 # From tutorial\n",
    "\n",
    "                while True:\n",
    "                    try:\n",
    "                        # Optimize gen_AtoB\n",
    "                        _, fakeB, summ = sess.run([self.g_A_trainer, self.gen_AtoB, self.g_A_loss_summ], feed_dict={\n",
    "                                                     self.image_A: next_image_A.get_next(),\n",
    "                                                     self.image_B: next_image_B.get_next(),\n",
    "                                                     self.learningRate: currentLearningRate\n",
    "                                                 })\n",
    "                        writer.add_sumary(summ, iteration)\n",
    "\n",
    "                        # Optimize discrim_B\n",
    "                        _, summ = sess.run([self.d_B_trainer, self.d_B_loss_summ], feed_dict={\n",
    "                                                     self.image_A: next_image_A.get_next(),\n",
    "                                                     self.image_B: next_image_B.get_next(),\n",
    "                                                     self.learningRate: currentLearningRate\n",
    "                                                 })\n",
    "                        writer.add_sumary(summ, iteration)\n",
    "\n",
    "                        # Optimize gen_BtoA\n",
    "                        _, fakeA, summ = sess.run([self.g_B_trainer, self.gen_BtoA, self.g_B_loss_summ], feed_dict={\n",
    "                                                     self.image_A: next_image_A.get_next(),\n",
    "                                                     self.image_B: next_image_B.get_next(),\n",
    "                                                     self.learningRate: currentLearningRate\n",
    "                                                 })\n",
    "                        writer.add_sumary(summ, iteration)\n",
    "\n",
    "                        # Optimize discrim_A\n",
    "                        _, summ = sess.run([self.d_A_trainer, self.d_A_loss_summ], feed_dict={\n",
    "                                                     self.image_A: next_image_A.get_next(),\n",
    "                                                     self.image_B: next_image_B.get_next(),\n",
    "                                                     self.learningRate: currentLearningRate\n",
    "                                                 })\n",
    "                        writer.add_sumary(summ, iteration)\n",
    "                    except tf.errors.OutOfRangeError:\n",
    "                        break\n",
    "                    \n",
    "                    # Increment iteration since we've finished another image\n",
    "                    sess.run(tf.assign(self.iteration, iteration+1))\n",
    "                \n",
    "                # Increment global step since we've finished another epoch\n",
    "                sess.run(tf.assign(self.global_step, epoch+1))\n",
    "\n",
    "        # Visually evaluate samples\n",
    "        #predictions = gan.predict(input_fn=lambda: test_input_fn(num_epochs, batch_size))\n",
    "\n",
    "        # TODO: Plot 'em"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Dimensions must be equal, but are 72 and 60 for 'sub' (op: 'Sub') with input shapes: [16,72,72,4], [16,60,60,4].",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m/usr/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[0;34m(graph, node_def, inputs, control_inputs)\u001b[0m\n\u001b[1;32m   1588\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1589\u001b[0;31m     \u001b[0mc_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_FinishOperation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop_desc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1590\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Dimensions must be equal, but are 72 and 60 for 'sub' (op: 'Sub') with input shapes: [16,72,72,4], [16,60,60,4].",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-2fb2a4070cf0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCycleGAN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-4-3bd88e58a5db>\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    161\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m         \u001b[0;31m# Define the networks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcyclegan_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m         \u001b[0;31m# Saving content checkpoints and summaries to disk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-3bd88e58a5db>\u001b[0m in \u001b[0;36mcyclegan_model\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0;31m# Generator should by cycle consistent & we want the discriminator to output a 1, i.e. incorrect label\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m         \u001b[0mcyc_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_mean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_A\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen_AtoBtoA\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m                    \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_mean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_B\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen_BtoAtoB\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m         \u001b[0mg_loss_A\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcyc_loss\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m10\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_mean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msquared_difference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisc_Afake\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m         \u001b[0mg_loss_B\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcyc_loss\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m10\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_mean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msquared_difference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisc_Bfake\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36mbinary_op_wrapper\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m    845\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    846\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 847\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    848\u001b[0m       \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSparseTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    849\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/site-packages/tensorflow/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36msub\u001b[0;34m(x, y, name)\u001b[0m\n\u001b[1;32m   8007\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0m_ctx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_eager_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_eager\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   8008\u001b[0m     _, _, _op = _op_def_lib._apply_op_helper(\n\u001b[0;32m-> 8009\u001b[0;31m         \"Sub\", x=x, y=y, name=name)\n\u001b[0m\u001b[1;32m   8010\u001b[0m     \u001b[0m_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   8011\u001b[0m     \u001b[0m_inputs_flat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[0;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    785\u001b[0m         op = g.create_op(op_type_name, inputs, output_types, name=scope,\n\u001b[1;32m    786\u001b[0m                          \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattr_protos\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 787\u001b[0;31m                          op_def=op_def)\n\u001b[0m\u001b[1;32m    788\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0moutput_structure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_stateful\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mcreate_op\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_shapes, compute_device)\u001b[0m\n\u001b[1;32m   3412\u001b[0m           \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3413\u001b[0m           \u001b[0moriginal_op\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_default_original_op\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3414\u001b[0;31m           op_def=op_def)\n\u001b[0m\u001b[1;32m   3415\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3416\u001b[0m       \u001b[0;31m# Note: shapes are lazily computed with the C API enabled.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, node_def, g, inputs, output_types, control_inputs, input_types, original_op, op_def)\u001b[0m\n\u001b[1;32m   1754\u001b[0m           op_def, inputs, node_def.attr)\n\u001b[1;32m   1755\u001b[0m       self._c_op = _create_c_op(self._graph, node_def, grouped_inputs,\n\u001b[0;32m-> 1756\u001b[0;31m                                 control_input_ops)\n\u001b[0m\u001b[1;32m   1757\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1758\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_c_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[0;34m(graph, node_def, inputs, control_inputs)\u001b[0m\n\u001b[1;32m   1590\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1591\u001b[0m     \u001b[0;31m# Convert to ValueError for backwards compatibility.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1592\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1593\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1594\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mc_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Dimensions must be equal, but are 72 and 60 for 'sub' (op: 'Sub') with input shapes: [16,72,72,4], [16,60,60,4]."
     ]
    }
   ],
   "source": [
    "g = CycleGAN()\n",
    "g.run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
